{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöó Addestramento Record Linkage (Ottimizzato per Esecuzione Locale)\n",
    "\n",
    "Questo notebook √® stato ottimizzato per essere leggero sulla CPU e gestire correttamente i file CSV locali.\n",
    "\n",
    "### Caratteristiche principali:\n",
    "- **Gestione Percorsi Hardware**: Rilevamento automatico della cartella `data/`.\n",
    "- **Efficienza Memoria**: Caricamento selettivo delle colonne e pulizia della cache.\n",
    "- **Visualizzazione Dati**: Visualizzazione chiara dei file CSV prima dell'esecuzione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Caricamento Dati\n",
    "Inizializziamo l'ambiente e carichiamo i dati con ottimizzazioni di memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'try' statement on line 28 (1241438918.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mgt_path = os.path.join('..', 'data', 'gt', 'gt_train.csv')\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'try' statement on line 28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import recordlinkage\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "# --- CONFIGURAZIONE PERCORSI ---\n",
    "# Cerchiamo la cartella data partendo dalla root del progetto\n",
    "base_path = os.getcwd()\n",
    "if 'notebooks' in base_path:\n",
    "    data_dir = os.path.join('..', 'data', 'processed')\n",
    "    results_dir = os.path.join('..', 'data', 'results')\n",
    "else:\n",
    "    data_dir = os.path.join('data', 'processed')\n",
    "    results_dir = os.path.join('data', 'results')\n",
    "\n",
    "cl_path = os.path.join(data_dir, 'craigslist_final.csv')\n",
    "us_path = os.path.join(data_dir, 'us_cars_final.csv')\n",
    "\n",
    "SAMPLE_SIZE = 50000  # Ridotto per efficienza locale, aumenta se necessario\n",
    "\n",
    "print(f\"üîç Ricerca dati in: {os.path.abspath(data_dir)}\")\n",
    "\n",
    "cols = ['make', 'model', 'year', 'fuel_type', 'transmission', 'body_type']\n",
    "\n",
    "try:\n",
    "    # Caricamento ottimizzato: solo colonne necessarie e tipi di dati efficienti\n",
    "    df_cl = pd.read_csv(cl_path, index_col='id_cl', usecols=['id_cl'] + cols)\n",
    "    df_us = pd.read_csv(us_path, index_col='id_us', usecols=['id_us'] + cols)\n",
    "    \n",
    "    # Campionamento per ridurre il carico computazionale\n",
    "    df_cl = df_cl.sample(n=min(SAMPLE_SIZE, len(df_cl)), random_state=42)\n",
    "    df_us = df_us.sample(n=min(SAMPLE_SIZE, len(df_us)), random_state=42)\n",
    "\n",
    "    print(\"‚úÖ Dati caricati con successo!\")\n",
    "    \n",
    "    # VISUALIZZAZIONE CSV\n",
    "    print(\"\\n--- Anteprima Craigslist Data ---\")\n",
    "    display(df_cl.head())\n",
    "    \n",
    "    print(\"\\n--- Anteprima US Cars Data ---\")\n",
    "    display(df_us.head())\n",
    "    \n",
    "    print(f\"\\nDimensioni Dataset: Craigslist={df_cl.shape}, US Cars={df_us.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERRORE: File non trovati in {data_dir}. Verifica la posizione dei CSV.\")\n",
    "    df_cl, df_us = None, None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRORE IMPREVISTO: {e}\")\n",
    "    df_cl, df_us = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Strategie Record Linkage (Manual)\n",
    "Eseguiamo i test B1 e B2 con gestione della memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Inizio Record Linkage - Strategia: B1\n",
      "üîπ Candidati individuati: 9277512\n",
      "‚è≥ Elaborazione in corso in blocchi da 1000000...\n",
      "‚úÖ Completato! Risultati salvati in: ..\\data\\results\\matches_rl_B1.csv (1126263 record)\n",
      "\n",
      "üöÄ Inizio Record Linkage - Strategia: B2\n",
      "üîπ Candidati individuati: 506212\n",
      "‚è≥ Elaborazione in corso in blocchi da 1000000...\n",
      "‚úÖ Completato! Risultati salvati in: ..\\data\\results\\matches_rl_B2.csv (506212 record)\n"
     ]
    }
   ],
   "source": [
    "import recordlinkage\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "def run_manual_rl_safe(strategy='B1'):\n",
    "    if df_cl is None or df_us is None:\n",
    "        print(\"‚ùå Dati non pronti. Carica prima i dataset.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüöÄ Inizio Record Linkage - Strategia: {strategy}\")\n",
    "    \n",
    "    # Inizializzazione dell'indexer per il blocking \n",
    "    indexer = recordlinkage.Index()\n",
    "    \n",
    "    # --- INTEGRAZIONE DELLE STRATEGIE B1 E B2 (Punto 4.D) ---\n",
    "    if strategy == 'B1':\n",
    "        # Strategia pi√π ampia: marca e anno [cite: 20]\n",
    "        indexer.block(['make', 'year']) \n",
    "    else:\n",
    "        # Strategia B2: pi√π restrittiva per massimizzare la precision [cite: 20]\n",
    "        indexer.block(['make', 'model', 'year']) \n",
    "    \n",
    "    # Generazione dei link candidati\n",
    "    links = indexer.index(df_cl, df_us)\n",
    "    print(f\"üîπ Candidati individuati: {len(links)}\")\n",
    "\n",
    "    # Definizione delle regole di confronto [cite: 21]\n",
    "    comp = recordlinkage.Compare()\n",
    "    comp.string('model', 'model', method='jarowinkler', threshold=0.85, label='model')\n",
    "    comp.exact('fuel_type', 'fuel_type', label='fuel')\n",
    "    comp.exact('transmission', 'transmission', label='transmission')\n",
    "\n",
    "    # --- SOLUZIONE AL MEMORY ERROR: CHUNKING ---\n",
    "    chunk_size = 1000000 \n",
    "    all_matches = []\n",
    "\n",
    "    print(f\"‚è≥ Elaborazione in corso in blocchi da {chunk_size}...\")\n",
    "    for i in range(0, len(links), chunk_size):\n",
    "        chunk = links[i:i + chunk_size]\n",
    "        \n",
    "        # Calcolo delle feature per il blocco attuale\n",
    "        features_chunk = comp.compute(chunk, df_cl, df_us)\n",
    "        \n",
    "        # Calcolo dello score pesato\n",
    "        features_chunk['score'] = (features_chunk['model'] * 3 + \n",
    "                                   features_chunk['fuel'] * 0.5 + \n",
    "                                   features_chunk['transmission'] * 0.5)\n",
    "        \n",
    "        # Salvataggio solo dei record sopra la soglia di confidenza\n",
    "        matches_chunk = features_chunk[features_chunk['score'] >= 3.0].reset_index()\n",
    "        all_matches.append(matches_chunk)\n",
    "        \n",
    "        # Pulizia della memoria\n",
    "        del features_chunk\n",
    "        gc.collect()\n",
    "\n",
    "    # Unione dei risultati e salvataggio\n",
    "    if all_matches:\n",
    "        final_matches = pd.concat(all_matches, ignore_index=True)\n",
    "        final_matches.rename(columns={'level_0': 'id_cl', 'level_1': 'id_us'}, inplace=True)\n",
    "        \n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        out_path = os.path.join(results_dir, f'matches_rl_{strategy}.csv')\n",
    "        final_matches[['id_cl', 'id_us', 'score']].to_csv(out_path, index=False)\n",
    "        print(f\"‚úÖ Completato! Risultati salvati in: {out_path} ({len(final_matches)} record)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Nessun match trovato per la strategia {strategy}.\")\n",
    "\n",
    "# --- ESECUZIONE DELLE DUE PIPELINE (Punto 4.H) ---\n",
    "run_manual_rl_safe('B1')\n",
    "run_manual_rl_safe('B2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dedupe Training (Machine Learning)\n",
    "Versione ottimizzata per non saturare la CPU locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Indici df_cl: 50000 | df_us: 50000\n",
      "üîÑ Conversione dizionari...\n",
      "üìñ Lettura Ground Truth...\n",
      "‚úÖ Coppie pronte: 11 Match, 1000 Distinct.\n",
      "üß™ Preparazione training...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dedupe\n",
    "import csv\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "def run_dedupe_with_gt(df_cl, df_us, results_dir, gt_train_path, gt_negatives_path=None):\n",
    "    if df_cl is None or df_us is None:\n",
    "        print(\"‚ùå Dati non pronti.\")\n",
    "        return\n",
    "\n",
    "    print(f\"DEBUG: Indici df_cl: {len(df_cl)} | df_us: {len(df_us)}\")\n",
    "\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    settings_file = os.path.join(results_dir, 'dedupe_learned_settings')\n",
    "    training_file = os.path.join(results_dir, 'dedupe_training.json')\n",
    "\n",
    "    fields = [\n",
    "        dedupe.variables.String('make', has_missing=True),\n",
    "        dedupe.variables.String('model', has_missing=True),\n",
    "        dedupe.variables.Exact('year', has_missing=True),\n",
    "        dedupe.variables.String('body_type', has_missing=True)\n",
    "    ]\n",
    "\n",
    "    def to_dedupe_dict(df, fields_list):\n",
    "        field_names = [f.field for f in fields_list]\n",
    "        data_dict = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            record = {field: (str(row.get(field)) if pd.notna(row.get(field)) else None) for field in field_names}\n",
    "            clean_id = str(int(idx)) if isinstance(idx, (int, float)) else str(idx)\n",
    "            data_dict[clean_id] = record\n",
    "        return data_dict\n",
    "\n",
    "    print(\"üîÑ Conversione dizionari...\")\n",
    "    data_1 = to_dedupe_dict(df_cl, fields)\n",
    "    data_2 = to_dedupe_dict(df_us, fields)\n",
    "\n",
    "    if os.path.exists(settings_file):\n",
    "        print(f\"üìÇ Caricamento impostazioni esistenti...\")\n",
    "        with open(settings_file, 'rb') as f:\n",
    "            linker = dedupe.StaticRecordLink(f)\n",
    "    else:\n",
    "        linker = dedupe.RecordLink(fields)\n",
    "        \n",
    "        labeled_examples = {'match': [], 'distinct': []}\n",
    "        print(f\"üìñ Lettura Ground Truth...\")\n",
    "        gt_df = pd.read_csv(gt_train_path)\n",
    "        \n",
    "        for _, row in gt_df.iterrows():\n",
    "            id_1, id_2 = str(int(row['id_cl'])), str(int(row['id_us']))\n",
    "            if id_1 in data_1 and id_2 in data_2:\n",
    "                pair = (data_1[id_1], data_2[id_2])\n",
    "                if int(row.get('label', 1)) == 1:\n",
    "                    labeled_examples['match'].append(pair)\n",
    "                else:\n",
    "                    labeled_examples['distinct'].append(pair)\n",
    "\n",
    "        # Generazione esempi negativi automatica\n",
    "        if len(labeled_examples['distinct']) < 500:\n",
    "            ids_1, ids_2 = list(data_1.keys()), list(data_2.keys())\n",
    "            while len(labeled_examples['distinct']) < 1000:\n",
    "                i1, i2 = random.choice(ids_1), random.choice(ids_2)\n",
    "                if data_1[i1]['make'] != data_2[i2]['make']:\n",
    "                    labeled_examples['distinct'].append((data_1[i1], data_2[i2]))\n",
    "\n",
    "        print(f\"‚úÖ Coppie pronte: {len(labeled_examples['match'])} Match, {len(labeled_examples['distinct'])} Distinct.\")\n",
    "\n",
    "        # --- MODIFICA CRITICA QUI ---\n",
    "        print(\"üß™ Preparazione training...\")\n",
    "        # Usiamo come sample_size il numero totale di record che abbiamo caricato\n",
    "        # Questo garantisce che Dedupe indicizzi TUTTI i record, inclusi quelli della GT\n",
    "        total_sample = max(len(data_1), len(data_2))\n",
    "        linker.prepare_training(data_1, data_2, sample_size=total_sample)\n",
    "        \n",
    "        try:\n",
    "            linker.mark_pairs(labeled_examples)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Problema con mark_pairs: {e}\")\n",
    "            print(\"Provo a resettare l'indice di training...\")\n",
    "            # Fallback estremo: forziamo un numero ancora pi√π alto\n",
    "            linker.prepare_training(data_1, data_2, sample_size=len(data_1) + len(data_2))\n",
    "            linker.mark_pairs(labeled_examples)\n",
    "\n",
    "        print(\"üß† Addestramento modello...\")\n",
    "        linker.train()\n",
    "\n",
    "        with open(training_file, 'w') as tf:\n",
    "            linker.write_training(tf)\n",
    "        with open(settings_file, 'wb') as sf:\n",
    "            linker.write_settings(sf)\n",
    "\n",
    "    print(\"üîó Esecuzione Join...\")\n",
    "    # Il join pu√≤ essere pesante, usiamo i blocchi (blocking) per non saturare la RAM\n",
    "    matches = linker.join(data_1, data_2, threshold=0.5)\n",
    "    \n",
    "    out_path = os.path.join(results_dir, 'matches_dedupe_final.csv')\n",
    "    with open(out_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['cl_id', 'us_id', 'confidence'])\n",
    "        for (id1, id2), score in matches:\n",
    "            writer.writerow([id1, id2, score])\n",
    "            \n",
    "    print(f\"‚ú® Completato! Risultati in: {out_path}\")\n",
    "    gc.collect()\n",
    "\n",
    "results_dir = \"results_integration\"\n",
    "gt_path = os.path.join('..', 'data', 'gt', 'gt_train.csv')\n",
    "\n",
    "run_dedupe_with_gt(df_cl, df_us, results_dir, gt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
